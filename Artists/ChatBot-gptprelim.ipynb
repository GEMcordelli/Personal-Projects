{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a1f091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 'Duke  Duke  Duke  Duke of Earl' 'Duke  Duke  Duke of Earl' 'Duke  Duke  Duke of Earl' 'Duke  Duke  Duke of Earl' 'Duke  Duke  Duke of Earl' 'Duke  Duke  Duke of Earl' 'Duke  Duke  Duke of Earl' 'Duke  Duke  Duke of Earl' 'As I walk through this world' 'Nothing can stop the Duke of Earl' 'And-a \n"
     ]
    }
   ],
   "source": [
    "# Make One Big String so the model can learn its cohesive structre for next token, etc.\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"Songs/OUTPUTS/AllSongs_Cleaned.csv\", sep='\\t', encoding='utf-8')\n",
    "\n",
    "# Optional: sort if necessary (you want the original order of words)\n",
    "#df = df.sort_values(by=['line_number', 'token_number'])\n",
    "\n",
    "# Concatenate into a single string\n",
    "text = ' '.join(df['chunk_str'].astype(str).tolist())\n",
    "\n",
    "# Let's see what it looks like\n",
    "print(text[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d6bb1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\grozz\\miniconda3\\envs\\gemcordelli\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\grozz\\miniconda3\\envs\\gemcordelli\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\grozz\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Load pre-trained tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Optional: Add special tokens if needed\n",
    "tokenizer.pad_token = tokenizer.eos_token  # GPT2 doesn't have a pad token, just reuse eos\n",
    "\n",
    "# Tokenize your text\n",
    "tokens = tokenizer(text, return_tensors='pt', truncation=True)\n",
    "\n",
    "# Check out the size\n",
    "print(tokens['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a638a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, tokens, block_size=128):\n",
    "        self.input_ids = tokens['input_ids'][0]\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.input_ids[idx:idx + self.block_size]\n",
    "        y = self.input_ids[idx + 1:idx + 1 + self.block_size]\n",
    "        return x, y\n",
    "\n",
    "dataset = LyricsDataset(tokens, block_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ba7ad27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 0 | Loss: 7.1051\n",
      "Epoch 0 | Step 256 | Loss: 5.7210\n",
      "Epoch 0 | Step 512 | Loss: 5.7310\n",
      "Epoch 0 | Step 768 | Loss: 6.0344\n",
      "Epoch 1 | Step 0 | Loss: 3.8072\n",
      "Epoch 1 | Step 256 | Loss: 4.8660\n",
      "Epoch 1 | Step 512 | Loss: 4.8592\n",
      "Epoch 1 | Step 768 | Loss: 5.1227\n",
      "Epoch 2 | Step 0 | Loss: 3.4993\n",
      "Epoch 2 | Step 256 | Loss: 4.0413\n",
      "Epoch 2 | Step 512 | Loss: 3.9977\n",
      "Epoch 2 | Step 768 | Loss: 4.1741\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "from torch.optim import AdamW\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model.resize_token_embeddings(len(tokenizer))  # adjust vocab size if you changed it\n",
    "model.train()\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training loop (tiny version)\n",
    "for epoch in range(3):\n",
    "    for i in range(0, len(dataset), 32):  # batch of 32\n",
    "        batch = [dataset[j] for j in range(i, min(i + 32, len(dataset)))]\n",
    "        x_batch = torch.stack([item[0] for item in batch])\n",
    "        y_batch = torch.stack([item[1] for item in batch])\n",
    "\n",
    "        outputs = model(input_ids=x_batch, labels=y_batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if i % 256 == 0:\n",
    "            print(f\"Epoch {epoch} | Step {i} | Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37c927ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "love is  You your  You wanna it' Cause butt  round   round  to waist - round round    To your round' 'm of -ake I it  And't me't  I of\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "prompt = \"love is\"\n",
    "inputs = tokenizer(prompt, return_tensors='pt')\n",
    "outputs = model.generate(inputs['input_ids'], max_length=50, do_sample=True, top_k=40)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7358523",
   "metadata": {},
   "source": [
    "### Let's Clean a Bit More\n",
    "\n",
    "In order to better understand our data, and eventually add more songs for a more livelu (and accurate) chatbot, let's...\n",
    "    \n",
    "    - normalize our words (get rid of trailing regexes that will mess up our pos tagger)\n",
    "\n",
    "    - add a title column (to differentiate sentiment from song to song)\n",
    "\n",
    "    - *Down the line, we want to do the same for the bottom 100 songs from the top 100, and look for differences in parameter quality*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f1fa484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "TOKENS = pd.read_csv(\"Songs/OUTPUTS/TOKENS_AllSongs.csv\", sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86409ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line_id</th>\n",
       "      <th>Song_id</th>\n",
       "      <th>Token_num</th>\n",
       "      <th>token_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Song 0</td>\n",
       "      <td>0</td>\n",
       "      <td>'Duke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Song 0</td>\n",
       "      <td>1</td>\n",
       "      <td>Duke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Song 0</td>\n",
       "      <td>2</td>\n",
       "      <td>Duke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Song 0</td>\n",
       "      <td>3</td>\n",
       "      <td>Duke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Song 0</td>\n",
       "      <td>4</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Line_id Song_id  Token_num token_str\n",
       "0        1  Song 0          0     'Duke\n",
       "1        1  Song 0          1      Duke\n",
       "2        1  Song 0          2      Duke\n",
       "3        1  Song 0          3      Duke\n",
       "4        1  Song 0          4        of"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4128e5c7",
   "metadata": {},
   "source": [
    "### 1) Normalize token_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5fb3476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Clean punctuation from token_str\n",
    "TOKENS['token_str'] = TOKENS['token_str'].str.replace(r\"^[^\\w]+|[^\\w]+$\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f635fc90",
   "metadata": {},
   "source": [
    "### 2) Adding Song Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db19f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_map = {\n",
    "    'Song 0': 'Duke of Earl',\n",
    "    'Song 1': 'Love in This Club',\n",
    "    'Song 3' : 'Bump, Bump, Bump',\n",
    "    'Song 4': 'Maria Maria',\n",
    "    'Song 5': 'Baby Got Back',\n",
    "    'Song 6' : 'Get Busy',\n",
    "    'Song 7' : 'Bump, Bump, Bump',\n",
    "    'Song 8' : 'Let Me Love You',\n",
    "    'Song 9': 'My Love',\n",
    "    'Song 10' : 'Only Girl (In The World)',\n",
    "    'Song 11' : 'Bennie',\n",
    "    'Song 12' : 'Shake It Off',\n",
    "    'Song 13' : 'Slow Jamz',\n",
    "    'Song 14' : 'The Streak',\n",
    "    # Add more as needed\n",
    "}\n",
    "\n",
    "TOKENS['alt_id'] = TOKENS['Song_id'].map(song_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "310bf788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line_id</th>\n",
       "      <th>Song_id</th>\n",
       "      <th>Token_num</th>\n",
       "      <th>token_str</th>\n",
       "      <th>alt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Song 0</td>\n",
       "      <td>0</td>\n",
       "      <td>Duke</td>\n",
       "      <td>Duke of Earl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Song 0</td>\n",
       "      <td>1</td>\n",
       "      <td>Duke</td>\n",
       "      <td>Duke of Earl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Song 0</td>\n",
       "      <td>2</td>\n",
       "      <td>Duke</td>\n",
       "      <td>Duke of Earl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Song 0</td>\n",
       "      <td>3</td>\n",
       "      <td>Duke</td>\n",
       "      <td>Duke of Earl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Song 0</td>\n",
       "      <td>4</td>\n",
       "      <td>of</td>\n",
       "      <td>Duke of Earl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7985</th>\n",
       "      <td>898</td>\n",
       "      <td>Song 14</td>\n",
       "      <td>1</td>\n",
       "      <td>at</td>\n",
       "      <td>The Streak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986</th>\n",
       "      <td>898</td>\n",
       "      <td>Song 14</td>\n",
       "      <td>2</td>\n",
       "      <td>that</td>\n",
       "      <td>The Streak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7987</th>\n",
       "      <td>898</td>\n",
       "      <td>Song 14</td>\n",
       "      <td>3</td>\n",
       "      <td>look</td>\n",
       "      <td>The Streak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7988</th>\n",
       "      <td>898</td>\n",
       "      <td>Song 14</td>\n",
       "      <td>4</td>\n",
       "      <td>at</td>\n",
       "      <td>The Streak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7989</th>\n",
       "      <td>898</td>\n",
       "      <td>Song 14</td>\n",
       "      <td>5</td>\n",
       "      <td>that</td>\n",
       "      <td>The Streak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7990 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Line_id  Song_id  Token_num token_str        alt_id\n",
       "0           1   Song 0          0      Duke  Duke of Earl\n",
       "1           1   Song 0          1      Duke  Duke of Earl\n",
       "2           1   Song 0          2      Duke  Duke of Earl\n",
       "3           1   Song 0          3      Duke  Duke of Earl\n",
       "4           1   Song 0          4        of  Duke of Earl\n",
       "...       ...      ...        ...       ...           ...\n",
       "7985      898  Song 14          1        at    The Streak\n",
       "7986      898  Song 14          2      that    The Streak\n",
       "7987      898  Song 14          3      look    The Streak\n",
       "7988      898  Song 14          4        at    The Streak\n",
       "7989      898  Song 14          5      that    The Streak\n",
       "\n",
       "[7990 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e3260e",
   "metadata": {},
   "source": [
    "### Tag Our TOKEN TABLE for POS Using SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00ead3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Example: assuming you have your DataFrame of tokens\n",
    "# and want to re-assemble them per line\n",
    "line_texts = TOKENS.groupby('Line_id')['token_str'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Process each line with spaCy\n",
    "pos_results = []\n",
    "\n",
    "for line_id, line_text in line_texts.items():\n",
    "    doc = nlp(line_text)\n",
    "    for token in doc:\n",
    "        pos_results.append({\n",
    "            'Line_id': line_id,\n",
    "            'token_str': token.text,\n",
    "            'pos': token.tag_,\n",
    "            'lemma': token.lemma_\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "tagged_df = pd.DataFrame(pos_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97d6f1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line_id</th>\n",
       "      <th>token_str</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Duke</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Duke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Duke</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Duke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Duke</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Duke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Duke</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Duke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Line_id token_str  pos lemma\n",
       "0        1      Duke  NNP  Duke\n",
       "1        1      Duke  NNP  Duke\n",
       "2        1      Duke  NNP  Duke\n",
       "3        1      Duke  NNP  Duke\n",
       "4        1        of   IN    of"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7720a0e",
   "metadata": {},
   "source": [
    "### Merge With TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f924825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_df['Token_num'] = tagged_df.groupby('Line_id').cumcount()\n",
    "TOKENS = TOKENS.merge(tagged_df, on=['Line_id', 'Token_num'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf5c7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS = TOKENS.set_index(['Line_id', 'Song_id', 'alt_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c2cff2",
   "metadata": {},
   "source": [
    "### Add Sentiment Lexicon ~ SALEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d71e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "SALEX = pd.read_csv(\"salex_nrc.csv\").set_index('term_str')\n",
    "SALEX.columns = [col.replace('nrc_','') for col in SALEX.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e9215ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandonment</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abduction</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aberration</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youth</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zeal</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zealous</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zest</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3688 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             anger  anticipation  disgust  fear  joy  negative  positive  \\\n",
       "term_str                                                                   \n",
       "abandon          0             0        0     1    0         1         0   \n",
       "abandoned        1             0        0     1    0         1         0   \n",
       "abandonment      1             0        0     1    0         1         0   \n",
       "abduction        0             0        0     1    0         1         0   \n",
       "aberration       0             0        1     0    0         1         0   \n",
       "...            ...           ...      ...   ...  ...       ...       ...   \n",
       "young            0             1        0     0    1         0         1   \n",
       "youth            1             1        0     1    1         0         1   \n",
       "zeal             0             1        0     0    1         0         1   \n",
       "zealous          0             0        0     0    1         0         1   \n",
       "zest             0             1        0     0    1         0         1   \n",
       "\n",
       "             sadness  surprise  trust  sentiment  \n",
       "term_str                                          \n",
       "abandon            1         0      0         -1  \n",
       "abandoned          1         0      0         -1  \n",
       "abandonment        1         1      0         -1  \n",
       "abduction          1         1      0         -1  \n",
       "aberration         0         0      0         -1  \n",
       "...              ...       ...    ...        ...  \n",
       "young              0         1      0          1  \n",
       "youth              0         1      0          1  \n",
       "zeal               0         1      1          1  \n",
       "zealous            0         0      1          1  \n",
       "zest               0         0      1          1  \n",
       "\n",
       "[3688 rows x 11 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SALEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b063a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS.rename(columns={'token_str_x': 'term_str'}, inplace=True)\n",
    "\n",
    "emo_cols = \"anger anticipation disgust fear joy sadness surprise trust sentiment\".split()\n",
    "#TOKENS = TOKENS.join(SALEX, on='term_str', how='left')\n",
    "TOKENS[emo_cols] = TOKENS[emo_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "463827a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>term_str</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Line_id</th>\n",
       "      <th>Song_id</th>\n",
       "      <th>alt_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <th>Song 4</th>\n",
       "      <th>Maria Maria</th>\n",
       "      <td>a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <th>Song 8</th>\n",
       "      <th>Let Me Love You</th>\n",
       "      <td>should</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <th>Song 5</th>\n",
       "      <th>Baby Got Back</th>\n",
       "      <td>the</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <th>Song 8</th>\n",
       "      <th>Let Me Love You</th>\n",
       "      <td>know</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <th>Song 1</th>\n",
       "      <th>Love in This Club</th>\n",
       "      <td>Give</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <th>Song 5</th>\n",
       "      <th>Baby Got Back</th>\n",
       "      <td>fat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <th>Song 13</th>\n",
       "      <th>Slow Jamz</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <th>Song 8</th>\n",
       "      <th>Let Me Love You</th>\n",
       "      <td>even</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <th>Song 4</th>\n",
       "      <th>Maria Maria</th>\n",
       "      <td>She</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <th>Song 6</th>\n",
       "      <th>Get Busy</th>\n",
       "      <td>its</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  term_str  anger  anticipation  disgust  \\\n",
       "Line_id Song_id alt_id                                                     \n",
       "250     Song 4  Maria Maria              a    0.0           0.0      0.0   \n",
       "525     Song 8  Let Me Love You     should    0.0           0.0      0.0   \n",
       "279     Song 5  Baby Got Back          the    0.0           0.0      0.0   \n",
       "483     Song 8  Let Me Love You       know    0.0           0.0      0.0   \n",
       "31      Song 1  Love in This Club     Give    0.0           0.0      0.0   \n",
       "279     Song 5  Baby Got Back          fat    0.0           0.0      1.0   \n",
       "799     Song 13 Slow Jamz              sex    0.0           1.0      0.0   \n",
       "492     Song 8  Let Me Love You       even    0.0           0.0      0.0   \n",
       "259     Song 4  Maria Maria            She    0.0           0.0      0.0   \n",
       "372     Song 6  Get Busy               its    0.0           0.0      0.0   \n",
       "\n",
       "                                   fear  joy  sadness  surprise  trust  \\\n",
       "Line_id Song_id alt_id                                                   \n",
       "250     Song 4  Maria Maria         0.0  0.0      0.0       0.0    0.0   \n",
       "525     Song 8  Let Me Love You     0.0  0.0      0.0       0.0    0.0   \n",
       "279     Song 5  Baby Got Back       0.0  0.0      0.0       0.0    0.0   \n",
       "483     Song 8  Let Me Love You     0.0  0.0      0.0       0.0    0.0   \n",
       "31      Song 1  Love in This Club   0.0  0.0      0.0       0.0    0.0   \n",
       "279     Song 5  Baby Got Back       0.0  0.0      1.0       0.0    0.0   \n",
       "799     Song 13 Slow Jamz           0.0  1.0      0.0       0.0    1.0   \n",
       "492     Song 8  Let Me Love You     0.0  0.0      0.0       0.0    0.0   \n",
       "259     Song 4  Maria Maria         0.0  0.0      0.0       0.0    0.0   \n",
       "372     Song 6  Get Busy            0.0  0.0      0.0       0.0    0.0   \n",
       "\n",
       "                                   sentiment  \n",
       "Line_id Song_id alt_id                        \n",
       "250     Song 4  Maria Maria              0.0  \n",
       "525     Song 8  Let Me Love You          0.0  \n",
       "279     Song 5  Baby Got Back            0.0  \n",
       "483     Song 8  Let Me Love You          0.0  \n",
       "31      Song 1  Love in This Club        0.0  \n",
       "279     Song 5  Baby Got Back           -1.0  \n",
       "799     Song 13 Slow Jamz                1.0  \n",
       "492     Song 8  Let Me Love You          0.0  \n",
       "259     Song 4  Maria Maria              0.0  \n",
       "372     Song 6  Get Busy                 0.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS[['term_str'] + emo_cols].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4cdab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemcordelli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
